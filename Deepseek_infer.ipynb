{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c769bf8-156c-464e-9ae0-e3d6938590ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baskar/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:03<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftConfig, PeftModel\n",
    "import gradio as gr\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"baskarm/deepseek-coder-7b-instruct-v1.5_finetune\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "config = PeftConfig.from_pretrained(\"baskarm/deepseek-coder-7b-instruct-v1.5_finetune\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\", quantization_config=bnb_config).eval()\n",
    "model = PeftModel.from_pretrained(base_model, \"baskarm/deepseek-coder-7b-instruct-v1.5_finetune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c057ca8-e41f-457b-9ec5-19bbc056637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_gen(question, history):\n",
    "    messages=[\n",
    "        { 'role': 'user', 'content': question}\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82494ccb-98bb-4d8d-8f20-f5f9c0472aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 4.27.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://a620c4e56cfb9230f9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a620c4e56cfb9230f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baskar/miniconda3/envs/llm/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:538: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100015 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100015 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100015 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100015 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "js = \"\"\"\n",
    "function createGradioAnimation() {\n",
    "    var container = document.createElement('div');\n",
    "    container.id = 'gradio-animation';\n",
    "    container.style.fontSize = '2em';\n",
    "    container.style.fontWeight = 'bold';\n",
    "    container.style.textAlign = 'center';\n",
    "    container.style.marginBottom = '120px';\n",
    "\n",
    "    var text = 'Code-Gen+Completion';\n",
    "    for (var i = 0; i < text.length; i++) {\n",
    "        (function(i){\n",
    "            setTimeout(function(){\n",
    "                var letter = document.createElement('span');\n",
    "                letter.style.opacity = '0';\n",
    "                letter.style.transition = 'opacity 0.05s';\n",
    "                letter.innerText = text[i];\n",
    "\n",
    "                container.appendChild(letter);\n",
    "\n",
    "                setTimeout(function() {\n",
    "                    letter.style.opacity = '1';\n",
    "                }, 50);\n",
    "            }, i * 250);\n",
    "        })(i);\n",
    "    }\n",
    "\n",
    "    var gradioContainer = document.querySelector('.gradio-container');\n",
    "    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n",
    "    document.body.style.backgroundImage = \"url(https://companiesmarketcap.com/img/company-logos/256/CALX.webp)\";\n",
    "    return 'Animation created';\n",
    "}\n",
    "\"\"\"\n",
    "css=\"\"\".gradio-container{\n",
    "  /* The image used */\n",
    "  background-image: url(https://companiesmarketcap.com/img/company-logos/256/CALX.webp);\n",
    "  /* Center and scale the image nicely */\n",
    "  object-position : top-left;\n",
    "  background-repeat: no-repeat;\n",
    "}\"\"\"\n",
    "demo = gr.ChatInterface(code_gen, css=css, js=js)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad5cba-5d9d-42a6-bdc2-49113f3e75e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161149f7-e210-4b49-aa7c-0775419d6e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf236c9-d0f6-4958-b6a6-a3f6ee14ed0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
